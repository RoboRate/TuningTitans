<!DOCTYPE html>
<html lang="en">
<head>
  <head>
    <link rel="shortcut icon" href="{{ url_for('static', filename='/images/Roboo.png') }}" />
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Benchmark</title>
    <link rel="stylesheet" href="{{ url_for('static', filename='/css/neon.css') }}" />
  </head>
<body>
  <h2 class="center1">
    <a href="/">Q&A Design</a>
    <a href="/finetuning">Fine-tuning</a>
    <a href="/benchmarkPage">Benchmark</a>
  </h2>

  <div id="loading-overlay" class="overlay">
    <div class="loader"></div>
    <p>處理中，請稍後...</p>
  </div>

  <form action="/benchmark" method="post" enctype="multipart/form-data" id="benchmark-form">
    <div class="form-group">
      <label for="fine_tuned_model_id">Finetuned Model Name<span style="color:red">*</span>:</label>
      <input type="text" id="submit" name="fine_tuned_model_id" required />
    </div>
    <h4 class="center">Q&A 問答*:</h4>
    <div class="form-group">
      <label for="qna_data">上傳資料:</label>
      <input type="file" id="qna_data" name="qna_data" accept=".jsonl" required />
    </div>
    <div class="form-group-button">
      <input id="submit" type="submit" value="提交" />
    </div>
    <br>
    <text class="center">上傳資料格式限定為 jsonl （最多十題），例如：
    <br>{"prompt": "{想測試的問題}", "completion": "{標準答案}"}
    </text>
    <h3>
      {"prompt": "******西式餐廳二樓使用變質馬鈴薯炒菜,然後進行售賣。諮詢如何處理。\n請問這是食品安全問題或非食品安全問題?\n", "completion": "是食品安全問題\n"}<br />
      {"prompt": "諮詢如何辦理餐飲行業的食品經營許可證。\n請問這是食品安全問題或非食品安全問題?\n", "completion": " 非食品安全問題\n"} <br />
      {"prompt": "擺攤店家報有人在吃霸王餐。\n請問這是食品安全問題或非食品安全問題?\n", "completion": "非食品安全問題\n"} <br />
      <br/>
    </h3>
    <label class="center">Context: </label>
    <label class="center">
      （使用以下 prompt 讓 GPT-3.5-turbo 對模型回答的答案與標準答案的差異打分數）</label>
    <h3>您是一個評分的老師，請透過學生的實際回答與標準回答的內容比較來做評估。<br />
      評估學生的實際回答問題的表現。</h3>
    <h3>
      [評分邏輯]：<br />
      1. 將實際回答內容與標準回答內容進行比較，忽略風格、語法、順序或標點的差異。<br />
      2. 對於提出的問題，評估學生是否有回答相對應的答案，並且將學生的實際回答與標準回答進行比較。<br />
      3. 實際回答可能是標準回答的子集或超集，或者可能與標準回答有衝突。<br />
      [評分邏輯結束]</h3>
    <h3>
      請你確定下方哪種情況適用，給予每個回答分數（最低0分~最高10分），並且回覆數字：<br />
      (0分) 實際回答跟標準回答沒有任何交集。<br />
      (1~3分) 實際回答只包含部分標準回答內容。<br />
      (4~6分) 實際回答大部分包含標準回答。<br />
      (7~10分) 實際回答與標準回答的內容相符。</h3>
    
    <h4 class="center" id="BenchmarkReport">產出 Benchmark Report</h4>
    <label>Your model's answer:</label><br>
    <hr />
    {% for entry in results %}
    <label>Model Name:</label>
    <pre> {{ entry.model_name }}</pre>
    <label >Your model's answer sheet:</label>
    <pre>{{ entry.model_result | replace(', ', '<br>') |safe }}</pre>
    <label >Your model's score</label>
    <pre>{{ entry.model_evaluation | replace(', ', '<br>') | safe  }}</pre>
    <hr />

    {% endfor %}

    <h3>
      說明:<br>
      Question - Q&A問答裡的問題<br>
      YourModelAnswer - 模型的回答<br>
      IdealAnswer - Q&A問答裡的標準答案<br></h3>

  </form>
</body>
<script>
  {% if scrollToResult %}
    document.addEventListener("DOMContentLoaded", function(event) {
        var targetElement = document.getElementById("{{ scrollToResult }}");
        if (targetElement) {
            window.scrollTo(0, targetElement.offsetTop);
        }
    });
  {% endif %}

  document.addEventListener("DOMContentLoaded", function(event) {
    var loadingOverlay = document.getElementById("loading-overlay");
    var benchmarkForm = document.getElementById("benchmark-form");

    if (benchmarkForm) {
      benchmarkForm.addEventListener("submit", function() {
        loadingOverlay.style.display = "block";
      });
    }
  });
</script>
</html>